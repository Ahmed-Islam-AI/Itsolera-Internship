{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d86689e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at model were not used when initializing TFBertForSequenceClassification: ['dropout_75']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the text for sentiment analysis: \n",
      "  @media print {\n",
      "    .ms-editor-squiggles-container {\n",
      "      display:none !important;\n",
      "    }\n",
      "  }\n",
      "  .ms-editor-squiggles-container {\n",
      "    all: initial;\n",
      "  }i am going to kill you\n",
      "Sentiment: Negative\n",
      "Confidence: 0.90\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_save_path = 'model'\n",
    "tokenizer_save_path = 'tokenizer'\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained(model_save_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_save_path)\n",
    "\n",
    "# Function to make predictions\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors='tf', truncation=True, padding=True, max_length=512)\n",
    "    outputs = model(inputs)\n",
    "    predictions = tf.nn.softmax(outputs.logits, axis=-1)\n",
    "    label = tf.argmax(predictions, axis=1).numpy()[0]\n",
    "    return label, predictions.numpy()\n",
    "\n",
    "# Input text for sentiment analysis\n",
    "text = input(\"Enter the text for sentiment analysis: \")\n",
    "\n",
    "if text:\n",
    "    label, predictions = predict(text)\n",
    "    sentiment = \"Negative\" if label == 1 else \"Positive\"\n",
    "    print(f\"Sentiment: {sentiment}\")\n",
    "    print(f\"Confidence: {predictions[0][label]:.2f}\")\n",
    "else:\n",
    "    print(\"Please enter text to analyze.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b140e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
